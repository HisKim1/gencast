{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Concatenator For GenCast\n",
    "\n",
    "**필요한 Data**\n",
    "- surface level ERA5, precipitation 제외\n",
    "- surface level ERA5, precipitation 포함\n",
    "- pressure level ERA5\n",
    "- (optional) TOA solar incident radiation\n",
    "\n",
    "cmd에서 `.nc`로 변환하는 법\n",
    "```\n",
    "module load gcc/cdo-1.9.3\n",
    "cdo -f nc copy input.grib output.nc\n",
    "```\n",
    "\n",
    "[weatherbench2](https://console.cloud.google.com/storage/browser/weatherbench2/datasets/era5/1959-2022-1h-360x181_equiangular_with_poles_conservative.zarr?inv=1&invt=Abngtw&pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22)))에서 다운로드 가능할 수도?|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import his_utils\n",
    "import dask\n",
    "import cdsapi\n",
    "  \n",
    "# set up dataset path \n",
    "is_grib = True\n",
    "\n",
    "\n",
    "if is_grib:\n",
    "    ds_surface = \"concat_data/suf.grib\"\n",
    "    ds_surface_precip = \"concat_data/tp.grib\"\n",
    "    ds_pressure_level = \"concat_data/pres.grib\"\n",
    "    ds_surface_precip_prior = \"concat_data/tp_prior.grib\"\n",
    "else:\n",
    "    ds_surface = \"testdata/surface.nc\"\n",
    "    ds_surface_precip = \"testdata/precip.nc\"\n",
    "    ds_surface_precip_prior = None\n",
    "    ds_pressure_level = \"testdata/pressure.nc\"\n",
    "# ds_TOA = \"testdata/2022-01-01/2022-01-01 TOA.grib\"\n",
    "\n",
    "year = [\"2021\"]\n",
    "month = [\"06\"]\n",
    "day = 21\n",
    "time = [\"00:00\", \"12:00\"]\n",
    "\n",
    "if ds_surface_precip_prior is not None:\n",
    "    day_prior = [f\"{day-1}\"]\n",
    "    time_prior = [\n",
    "        \"12:00\", \"13:00\", \"14:00\", \"15:00\", \n",
    "        \"16:00\", \"17:00\", \"18:00\", \"19:00\",\n",
    "        \"20:00\", \"21:00\", \"22:00\", \"23:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cdsapi.Client()\n",
    "dataset = \"reanalysis-era5-pressure-levels\"\n",
    "request = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\"\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "P_level_13 = [\n",
    "    \"50\", \"100\", \"150\", \"200\", \"250\", \n",
    "    \"300\", \"400\", \"500\", \"600\",\"700\", \n",
    "    \"850\", \"925\", \"1000\"\n",
    "    ]\n",
    "\n",
    "dataset_single = \"reanalysis-era5-single-levels\"\n",
    "dataset_multi = \"reanalysis-era5-pressure-levels\"\n",
    "\n",
    "req_multi = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"variable\": [\n",
    "        \"geopotential\",\n",
    "        \"specific_humidity\",\n",
    "        \"temperature\",\n",
    "        \"u_component_of_wind\",\n",
    "        \"v_component_of_wind\",\n",
    "        \"vertical_velocity\"\n",
    "    ],\n",
    "    \"year\": year,\n",
    "    \"month\": month,\n",
    "    \"day\": [f\"{day}\"],\n",
    "    \"time\": time,\n",
    "    \"pressure_level\": P_level_13,\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    'grid': '1.0/1.0'\n",
    "}\n",
    "\n",
    "req_tp = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"variable\": [\"total_precipitation\"],\n",
    "    \"year\": year,\n",
    "    \"month\": month,\n",
    "    \"day\": [f\"{day}\"],\n",
    "    \"time\": [\n",
    "        \"00:00\", \"01:00\", \"02:00\",\n",
    "        \"03:00\", \"04:00\", \"05:00\",\n",
    "        \"06:00\", \"07:00\", \"08:00\",\n",
    "        \"09:00\", \"10:00\", \"11:00\",\n",
    "        \"12:00\", \"13:00\", \"14:00\",\n",
    "        \"15:00\", \"16:00\", \"17:00\",\n",
    "        \"18:00\", \"19:00\", \"20:00\",\n",
    "        \"21:00\", \"22:00\", \"23:00\"\n",
    "    ],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    'grid': '1.0/1.0'\n",
    "}\n",
    "\n",
    "req_surface = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"variable\": [\n",
    "        \"10m_u_component_of_wind\",\n",
    "        \"10m_v_component_of_wind\",\n",
    "        \"2m_temperature\",\n",
    "        \"mean_sea_level_pressure\",\n",
    "        \"sea_surface_temperature\",\n",
    "        \"toa_incident_solar_radiation\",\n",
    "        \"geopotential\",\n",
    "        \"land_sea_mask\"\n",
    "    ],\n",
    "    \"year\": year,\n",
    "    \"month\": month,\n",
    "    \"day\":[f\"{day}\"],\n",
    "    \"time\": time,\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    'grid': '1.0/1.0'\n",
    "}\n",
    "\n",
    "client.retrieve(\n",
    "    dataset_single,\n",
    "    req_tp,\n",
    "    ds_surface_precip\n",
    ")\n",
    "\n",
    "client.retrieve(\n",
    "    dataset_single,\n",
    "    req_surface,\n",
    "    ds_surface\n",
    ")\n",
    "\n",
    "client.retrieve(\n",
    "    dataset_multi,\n",
    "    req_multi,\n",
    "    ds_pressure_level\n",
    ")\n",
    "\n",
    "if ds_surface_precip_prior is not None:\n",
    "    req_tp_prior = {\n",
    "        \"product_type\": [\"reanalysis\"],\n",
    "        \"variable\": [\"total_precipitation\"],\n",
    "        \"year\": year,\n",
    "        \"month\": month,\n",
    "        \"day\": day_prior,\n",
    "        \"time\": [\n",
    "            \"00:00\", \"01:00\", \"02:00\",\n",
    "            \"03:00\", \"04:00\", \"05:00\",\n",
    "            \"06:00\", \"07:00\", \"08:00\",\n",
    "            \"09:00\", \"10:00\", \"11:00\",\n",
    "            \"12:00\", \"13:00\", \"14:00\",\n",
    "            \"15:00\", \"16:00\", \"17:00\",\n",
    "            \"18:00\", \"19:00\", \"20:00\",\n",
    "            \"21:00\", \"22:00\", \"23:00\"\n",
    "        ],\n",
    "        \"data_format\": \"grib\",\n",
    "        \"download_format\": \"unarchived\",\n",
    "    'grid': '1.0/1.0'\n",
    "    }\n",
    "\n",
    "    client.retrieve(    \n",
    "        dataset_single,\n",
    "        req_tp_prior,\n",
    "        ds_surface_precip_prior\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Surface Data w/o Precipitation\n",
    "\n",
    "precipitation 제외하고 받은 6-hrly data 전처리 하는 과정\n",
    "\n",
    "**TODO**\n",
    "- dimension 이름 변경\n",
    "- 불필요한 coordinate 삭제\n",
    "- variable 이름 변경 -> 나중에 합치고 한 번에 진행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_grib:\n",
    "    ds1 = xr.open_dataset(ds_surface, engine='cfgrib')\n",
    "    ds1 = ds1.drop_vars(['number', 'step', 'surface', 'valid_time'])\n",
    "    ds1 = ds1.rename({\"z\" : \"geopotential_at_surface\"})\n",
    "\n",
    "else:\n",
    "    ds1 = xr.open_dataset(ds_surface)\n",
    "    ds1 = ds1.rename({'var165':\"u10\",\n",
    "                      'var166':\"v10\", \n",
    "                      'var167':\"t2m\", \n",
    "                      'var129':\"geopotential_at_surface\", \n",
    "                      'var172':\"lsm\", \n",
    "                      'var151':\"msl\", \n",
    "                      'var34': \"sst\",\n",
    "                      'var212':\"tisr\"})\n",
    "ds1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Precipitation Data\n",
    "\n",
    "Accumulates 6-hour precipitation into the next time step?\n",
    "or into previous step?\n",
    "\n",
    "**TODO**\n",
    "- coordinate 정리\n",
    "- 강수량 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. the time after\n",
    "def sync_tp_coords(dataset: xr.Dataset):\n",
    "    dataset = dataset.stack(new_time=['time', 'step'])\n",
    "    dataset = dataset.assign_coords(new_time=dataset.valid_time.values)\n",
    "    dataset = dataset.rename({'new_time': 'time'})\n",
    "    dataset = dataset.drop_vars(['number', 'surface'])\n",
    "    return dataset\n",
    "\n",
    "if is_grib:\n",
    "    ds2 = xr.open_dataset(ds_surface_precip, engine='cfgrib')\n",
    "    if ds_surface_precip_prior is not None:\n",
    "        prior = xr.open_dataset(ds_surface_precip_prior, engine='cfgrib')\n",
    "        prior = sync_tp_coords(prior)\n",
    "\n",
    "    ds2 = sync_tp_coords(ds2)\n",
    "    ds2 = ds2.isel(time=slice(5,-7)) #                                          <------- FIX HERE\n",
    "else:\n",
    "    ds2 = xr.open_dataset(ds_surface_precip)\n",
    "    ds2 = ds2.rename({'var228': 'tp'})\n",
    "    if ds_surface_precip_prior is not None:\n",
    "        prior = xr.open_dataset(ds_surface_precip_prior)\n",
    "        prior = prior.rename({'var228': 'tp'})\n",
    "ds2.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. the time before\n",
    "if is_grib and ds_surface_precip_prior is not None:\n",
    "    prior = prior.isel(time=slice(5,29)) #                                        <------- FIX HERE\n",
    "else:\n",
    "    pass\n",
    "prior.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3. merge the two datasets\n",
    "if ds_surface_precip_prior is not None:\n",
    "    ds2 = xr.concat([prior, ds2], dim='time')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "ds2 = ds2.sortby('time')\n",
    "ds2 = ds2.resample(time='12h', closed='right', label='right').sum()\n",
    "ds2 = ds2.isel(time=slice(2, 4)) #                                           <------- FIX HERE\n",
    "ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pressure Level Data\n",
    "\n",
    "37 level data를 처리하는 과정. 17 level이어도 동일한 방식\n",
    "\n",
    "**TODO**\n",
    "- coordinate 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_grib:\n",
    "    ds3 = xr.open_dataset(ds_pressure_level, engine='cfgrib')\n",
    "    ds3 = ds3.drop_vars(['number', 'step', 'valid_time'])\n",
    "    ds3 = ds3.rename({\"isobaricInhPa\" : \"level\"})\n",
    "    ds3 = ds3.sortby('level', ascending=True)\n",
    "else:\n",
    "    ds3 = xr.open_dataset(ds_pressure_level)\n",
    "    ds3 = ds3.rename({'var130':\"t\", \n",
    "                      'var131':\"u\", \n",
    "                      'var132':\"v\", \n",
    "                      'var129':\"z\", \n",
    "                      'var133':\"q\", \n",
    "                      'var135':\"w\",\n",
    "                      'plev': \"level\"})\n",
    "    ds3['level'] = ds3['level']/100\n",
    "    ds3['level'].attrs['units'] = 'hPa'\n",
    "    ds3['level'].attrs['long_name'] = 'pressure level'\n",
    "ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = ds3.level.values\n",
    "level = level.astype(np.int32)\n",
    "\n",
    "ds3 = ds3.assign_coords(level = ('level', level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) 4. TOA 가공하기\n",
    "\n",
    "구글에서 만든 거랑 내가 다운받은거랑 같다면 상관 없음.\n",
    "다를 경우에는 이거 사용해야 함.\n",
    "\n",
    "$\\therefore$ $\\exists$ noise\n",
    "$\\Rightarrow$ 결과가 미묘하게 달라지지만 유의미해보이지는 않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th. TOA\n",
    "# ds4 = xr.open_dataset(ds_TOA, engine='cfgrib')\n",
    "\n",
    "# ds4 = ds4.stack(new_time=['time', 'step'])\n",
    "# ds4 = ds4.assign_coords(new_time=ds4.valid_time.values)\n",
    "# ds4 = ds4.rename({'new_time': 'time'})\n",
    "# ds4 = ds4.drop_vars(['number', 'surface', 'valid_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 3개의 데이터셋을 하나로 합성하기\n",
    "\n",
    "*ds1*, *ds2*, *ds3*, (*ds4*)를 하나로 합치고 GC에 잘 들어가도록 다듬어주기\n",
    "\n",
    "**TODO**\n",
    "- 한 장씩 합치는 게 좋을지, 여러 장 한 번에 합치는 게 좋을지 for memory efficiency\n",
    "- 합쳐서 GC에 잘 들어가는 지까지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets\n",
    "# ds_list = [ds1, ds2, ds3, ds4]\n",
    "ds_list = [ds1, ds2, ds3]\n",
    "\n",
    "result = xr.merge(ds_list)\n",
    "\n",
    "for ds in ds_list:\n",
    "    ds.close()\n",
    "\n",
    "result = his_utils.transform_dataset(result,\"12hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. 파일 명 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '/geodata2/S2S/DL/GC_input/2021-06-21/Gen_ERA5_input.nc'  #                     <------- FIX HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Output: GC로 준비 갈 완료!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_netcdf(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from google.cloud import storage\n",
    "\n",
    "# xr.open_zarr('gs://weatherbench2/datasets/era5/1959-2022-1h-360x181_equiangular_with_poles_conservative.zarr')\n",
    "# xr.open_zarr('gs://weatherbench2/datasets/era5-hourly-climatology/1990-2017_6h_1440x721.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = xr.open_dataset(\"/geodata2/S2S/DL/GC_input/source-era5_date-2019-03-29_res-1.0_levels-13_steps-12.nc\")\n",
    "original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# 번외: xarray.resample은 어떻게 작동하는가?\n",
    "\n",
    "| 1 | 2 | 3 | 4 | 5 | 6 | 7 | value\n",
    "\n",
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | hr\n",
    "\n",
    "`closed=` 어느 쪽을 닫힌 구간으로 쓸 것인가 $\\Rightarrow$ 어느 쪽을 포함하고 반대쪽을 제외할까\n",
    "\n",
    "`label=` sample한 거를 어느 쪽에 할당할 것인가\n",
    "\n",
    "- case 1) `xarray.resample(\"6h\")`\n",
    "\n",
    "    1 + ... + 6을 0hr에 할당\n",
    "\n",
    "- case 2) `xarray.resample(\"6h\", closed='right', label='right')`\n",
    "\n",
    "    2 + ... + 7을 6hr에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 샘플 데이터 생성 (0시부터 23시까지)\n",
    "date_range = pd.date_range(start='2021-12-31T19:00:00.000000000', end='2022-01-05T06:00:00.000000000', freq='h')\n",
    "data = np.arange(1, 109, 1)\n",
    "ds = pd.Series(data, index=date_range)\n",
    "\n",
    "# 6시간 간격으로 리샘플링\n",
    "ds_resampled = ds.resample('6h', closed='right', label='right').sum()\n",
    "\n",
    "print(\"\\n리샘플링 결과:\")\n",
    "print(ds_resampled)\n",
    "\n",
    "# 각 리샘플링 구간의 시작과 끝 확인\n",
    "for i, value in ds_resampled.items():\n",
    "    start = i\n",
    "    end = i + pd.Timedelta(hours=5)\n",
    "    original_data = ds[start:end]\n",
    "    print(f\"\\n{i}의 리샘플링 구간:\")\n",
    "    print(f\"시작: {start}, 끝: {end}\")\n",
    "    print(\"포함된 원본 데이터:\")\n",
    "    print(original_data)\n",
    "    print(f\"합계: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiskim1_graphcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
